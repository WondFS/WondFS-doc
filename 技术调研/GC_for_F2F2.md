# F2FS中垃圾回收优化

## Reducing garbage collection overhead of log-structured file systems with GC journaling

### 【问题描述】
在F2FS垃圾回收后，需要触发一次checkpoint用于更新文件系统状态，才能使得被更新的单元节（Section）才能投入重新使用。否则，系统发生crash后，倘若checkpoint利用到已回收的数据块进行系统恢复，则系统将一直崩溃。此外，checkpoint开销极大，每次垃圾回收都要触发checkpoint，开销巨大。

### 【解决方案】
本文提出一种GC journaling机制用于代替垃圾回收过程中Checkpointing。GCJ使用一个日志空间来记录GC移动的块的所有信息。使用日志，可以保证文件系统的一致性，而无需在系统崩溃时进行检查点。通过消除垃圾收集期间的检查点，进而可以显著降低垃圾收集延迟。如图所示，在迁移victim block时写入Journal entries。

![image](https://user-images.githubusercontent.com/33679152/170817892-74aab184-7554-46b3-8b4d-1d4e9f5444eb.png)

## Reinforcement Learning based Background Segment Cleaning for Log-structured File System on Mobile Devices

### 【摘要】
随着移动设备采用日志结构文件系统，后台段清理对系统性能和存储寿命的影响变得十分显著。 激进的后台段清理方案会产生过多的块迁移，损害NAND存储设备的耐用性，而常规的懒惰策略无法为后续的I/O请求回收足够的段，从而导致前台段清理的发生并延长I/O延迟。 在本文中，提出了一种基于强化学习的方法来平衡权衡，通过学习 I/O 工作负载的行为和逻辑地址空间的状态，所提出的方法可以自适应地将前台段清理的频率平均降低 68.57%，并且比现有方法减少 71.10% 的块迁移次数。

### 【背景】
通过以仅附加日志记录方式执行写入，LFS 设法减轻随机写入对系统性能的不利影响 [19]。 然而，这种异地更新方式会产生需要不时回收的无效逻辑块。 因此，段清理是 LFS 的一个重要组成部分。

LFS 维护两种类型的段清理，前台和后台段清理。前台段清理由写请求触发，在此期间LFS需要挂起写请求。结果，延长了用户 I/O 延迟。由于移动设备对系统响应的高度敏感，缓慢的 I/O 延迟可能会影响用户体验。为了缓解这个问题，定期进行后台段清理活动。挑战在于如何设置频率。激进的频率会导致过度的块迁移，这会产生额外的程序操作并损害闪存的耐用性。相比之下，懒惰的频率无法适应不同的工作负载行为。在密集的工作负载环境下，逻辑地址空间（LAS）中剩余的空闲空间可能不足以容纳后续的I/O请求，从而导致前台段清理的发生。在这种情况下，需要在移动设备的系统性能和存储寿命之间做出适当的权衡。

在这项工作中，提出了一种基于强化学习协助的后台段清理策略（RLBC）。 通过结合所有相关因素，RLBC 设法根据 逻辑地址空间LAS 的不同状态和工作负载行为自适应地做出清理决策。通过这种方式，可以平衡系统性能和闪存寿命之间的权衡。实验结果表明，与现有方法相比，所提出的方法可以有效地将前台段清理次数平均减少68.57%，同时将后台段清理中的块迁移次数减少71.10%。

### 【核心架构】
![image](https://user-images.githubusercontent.com/33679152/170818011-c2083bb1-697d-4d05-bcb5-38b1c47cc927.png)

图 5 描述了所提出方法的架构。在每个迭代步骤中，①RL 模型从环境（I/O 堆栈）中收集写入信息和 LAS 状态。有了这些信息，代理（BC 调度程序）可以识别 Q-table 中的当前状态。然后，它决定对 LFS 执行探索（随机选择一个未学习的动作）或利用（选择一个学习到的当前状态在 Q 表中具有最大 Q 值的动作）②③以在选定的时间间隔后实现后台段清理。后台段清理完成后，④agent收集块迁移数和回收块数。然后，agent根据更新后的 LAS 状态和写入信息再次感知状态。值得一提的是，每次清理后台段后，agent都会等待一段时间收集前台清理的触发时间，并根据公式3计算奖励。⑤最后将将来更新到Q-table中对应的条目中。

后台段清理是 LFS 的一个关键问题。激进的后台段清理会产生过度的块迁移，这会严重缩短移动闪存的使用寿命。 相比之下，后台片段清理不足可能会导致前台片段清理的发生，影响用户在移动设备上的体验。 为了解决这个问题，这项工作提出了 RLBC，这是一种基于强化学习的方法，可以自适应地决定何时触发后台片段清理。 评估结果表明，RLBC 设法减少了块迁移的次数，同时有效地减少了前景段清洗的发生。 以这种方式，系统性能随着存储寿命的延长而提高。


## ARS: Reducing F2FS Fragmentation for Smartphones using Decision Trees

### 【摘要】
众所周知，文件和可用空间碎片会对文件系统性能产生负面影响。 F2FS 是为闪存设计的文件系统。然而，由于其不及时更新和移动应用程序的高度同步、多线程写入行为，它遭受严重的碎片化。我们观察到碎片文件的运行时间比连续文件的运行时间长 2.36 倍，并且 F2FS 的就地更新方案无法减少碎片。碎片化的文件系统会导致糟糕的用户体验。 
保留空间以防止碎片化是一种直观的方法。但是，为所有文件保留空间会浪费空间，因为存在大量文件。为了解决这个困境，我们提出了一种自适应保留空间（ARS）方案来选择一些特定文件在保留空间中进行更新。如何有效地选择保留文件对性能至关重要。我们收集与碎片相关的文件特征来构建数据集并使用决策树来准确选择保留文件。此外，还采用了可调整预留空间和动态预留策略。我们在 HiKey960 开发平台和商用智能手机上实现 ARS，空间和文件创建时间开销很小。实验结果表明，与传统的 F2FS 和具有就地更新的 F2FS 相比，ARS 显着减少了文件和可用空间碎片，提高了文件 I/O 性能并减少了垃圾收集开销。此外，与传统的 F2FS 相比，ARS 在 SQLite 下每秒可提供高达 1.26 倍的事务，并减少了现实情况的运行时间。

### 【背景】
有两种类型的碎片，文件和可用空间碎片。 文件碎片是文件的离散数据范围，空闲空间碎片是分散的有效块。 它们相互交织。 如果一个文件被写成许多小的独立部分，它的碎片会切断连续的可用空间，这会增加可用空间碎片。 空闲空间碎片越重，新文件越碎片化。 频繁更新的应用程序并行地将新记录追加到不同的数据库文件中，这会导致严重的碎片化。

F2FS [6] 旨在按照日志结构的方法在闪存上提取更好的性能，是智能手机的理想文件系统。 但是，与大多数文件系统 [2] 类似，F2FS 会因碎片而变慢。 F2FS 不断更新新地址并在以后删除旧版本。有大量分散的漏洞（小的无效或空闲块）不能直接用于即将到来的文件，这需要垃圾收集 (GC)。

我们提出了 ARS，一种自适应保留空间方案，通过减少文件和可用空间碎片来提高智能手机中 F2FS 的性能。ARS的适配在于更新的保留文件、可调整的保留空间和可变的保留策略。与传统的碎片整理解决方案不同，例如将碎片数据复制在一起会缩短闪存寿命，ARS 会主动防止碎片，而不是复制数据。在动机实验中观察连续文件和碎片文件之间的性能差异，我们考虑了空间预留。但是，为所有文件保留空间会浪费空间并失去日志记录方案的优势。我们有选择地提取一些文件而不是所有文件以保留空间，这是基于观察到某些文件的读/写频率远高于其他文件。有大量经常访问的文件，并且很难手动选择保留文件。由于不同用户使用智能手机的方式不同，且用户有使用智能手机的个人习惯，因此痕迹之间存在差异和相似之处。我们过滤文件特征并根据其碎片程度和 I/O 行为添加分类标签以构建数据集。我们选择决策树来有效地选择保留文件。此外，我们将保留空间设置为一个段的倍数，并在文件系统空间利用率低时就地更新这些文件，在利用率高时回收未使用的保留空间。

### 【核心】
机器学习算法可实现对各种数据的高效分析并适应动态工作负载。 我们需要一种低成本、高精度的机器学习算法来有效地选择保留文件。
我们根据历史信息预测保留文件。是否为文件保留空间是一个两类问题。 最常用的分类算法是 k-最近邻 (KNN)、逻辑回归、决策树、AdaBoost 和随机森林。
![image](https://user-images.githubusercontent.com/33679152/170818257-361b3ade-1881-4583-a010-43671c0276c7.png)
![image](https://user-images.githubusercontent.com/33679152/170818260-2604d4a2-e0c8-4835-826a-e0f55dae06ad.png)

### 【总结】
在本文中，我们首先证明智能手机会生成大量碎片，无论是传统的还是提供就地更新的 F2FS。 我们提出了一种自适应保留空间 (ARS)方案，该方案使用决策树对保留文件进行分类并为其保留空间。 实验结果表明，ARS 在减少文件和空闲空间碎片、提高 I/O 性能和减少 GC 开销方面是有效的。ARS 在 SQLite、Facebook 和 Twitter 工作负载下的就地更新也优于传统的 F2FS和F2FS。

## SFP Smart File-Aware Prefetching for Flash based Storage system

### 【摘要】
目前，大多数基于Flash的存储系统通过数据预取来缩小主存和存储之间的性能差距。 然而，传统的预取技术在硬盘驱动器上表现良好，但在闪存上的有效性和效率有限。这是因为现代系统中复杂的数据访问模式没有得到很好的考虑。在本文中，我们提出了SFP，一种用于基于闪存的存储系统的智能文件感知预取方案。 SFP 展示了通过文件感知方法可以全面提高预取的准确性和效率。此外，提出了三种方案：文件访问模式学习、基于动态窗口的文件预取和学习模型大小优化。在真实服务器上的实验表明，与具有低内存和计算成本的最新技术相比，SFP 将访问延迟降低了 40%。

### 【背景】
然而，基于闪存的存储和主存之间的性能差距仍然很大[1][2]。更重要的是，随着应用的快速发展，用户访问性能的需求呈指数级增长。为了减少性能差距，最有效的方法之一是预取。 它的基本思想是在实际访问之前将数据读到主存。在现有系统中，例如 Linux，预读 [3] 已被广泛采用作为默认预取方案。该技术旨在按顺序预取数据。如果命中，则预取更多的顺序数据。否则，它是关闭的。这个想法与硬盘驱动器（HDD）的访问特性高度相关，硬盘驱动器具有良好的顺序访问性能。 然而，由于基于闪存的存储的不同访问特性以及现代工作负载的爆炸式增长，预读有很多限制。

与HDD不同，在基于Flash的存储系统中，顺序访问和随机访问之间的性能差异要小得多[4]。此外，随着现代工作负载的快速发展，访问模式更加复杂。设计预取方案以优化随机访问性能变得至关重要。以前，一些工作提出了基于 Flash 的存储系统的预取方案 [5][6][7][8][9]。这些工作中的大多数利用频繁的块访问模式来优化访问性能。然而，块 I/O 请求序列涉及的信息有限，并且许多不同的请求序列在调度后可能会交错。在这种情况下，对基于块信息的设计方案提出了挑战。更糟糕的是，他们都无法成功利用复杂的用户访问模式。还有一些工作专注于探索文件之间的相关性以进行预取。例如，[10] 和 [11] 被提议利用基于访问历史的文件访问模式，[12] 和 [13] 被提议利用元数据和数据文件之间的相关性。然而，随着现代工作负载的快速发展，应用程序变得更加复杂和随机。跟踪应用程序的访问模式以优化性能变得更具挑战性。与以往的工作不同，本文提出了一种通过访问模式学习的文件感知预取方案。

这篇论文的动机来自两个观察：首先，块级访问模式难以学习且容易受到干扰。传统的基于块的预取方案难以识别预取确定的模式。其次，文件级访问模式分析是预取的不错选择。文件级访问模式更容易识别，因为它与用户行为高度相关。基于这两个观察，本文提出了 SFP，一种智能文件感知预取方案，用于学习文件访问模式并预取文件以供将来访问。关键思想是获取文件访问序列，并使用马尔可夫模型或其他模型来学习访问模式。然后，基于模型，文件被预取到主存储器。使用这种基于文件的智能模型学习方案，预取可以准确并提供良好的文件访问性能。然而，有几个挑战需要解决。首先，如前所述，采用马尔可夫模型来记录和学习文件访问模式。有大量文件，需要记录和索引以进行训练。整个过程应该在线处理，计算和内存成本可以忽略不计。其次，训练完成后，预取线程被激活。在此阶段，应仔细控制预取精度。第三，马尔可夫模型的一个关键问题是其内存成本。由于训练好的模型应该一直保存在内存中，这会引入内存成本。以可忽略的预取精度成本最小化内存消耗非常重要。针对上述问题，本工作有以下贡献：
首先，提出了一种基于文件的访问模式学习方案。该方案是使用马尔可夫模型在线设计的。 如果文件是第一次访问，则会将其添加到模型中。 否则，根据访问信息更新其在模型中的相关值。 此外，许多访问的文件没有关联，它们被过滤掉以避免模型成本；

其次，提出了一种基于动态窗口的预取器。一个好的预取器需要满足时效性，减少资源浪费。 该方案采用动态窗口方式，可以根据预取精度调整窗口大小。

最后，进一步提出了一种基于差异文件的模型大小优化方案，以降低内存成本。基本上，没有相关性的文件应该记录在不同的模型中。然后，可以压缩模型。我们建议将模型划分为两个子模型，分别记录系统和用户文件。


### 【核心】
图 4 概述了在 VFS 中实施的拟议方案。该方案的基本思想是通过学习文件访问模式将数据预取到页面缓存中。在这种情况下，可以获得更复杂的用户行为，尤其是文件之间的切换，以提高预取效率，从而提升数据访问性能。然而，这个基本思想存在一些挑战：首先，应该基于文件访问序列构建一个有效的学习模型，文件访问序列与块访问序列相比要复杂得多。每个文件都用文件路径和文件名标识。在模式学习过程中，每个文件访问都应该被记录和索引，这应该被有效地设计。其次，一个好的预取器应该同时满足主机请求的预测准确性和及时性要求。如果请求早于预取器到达，则预取器将毫无用处，甚至会降低整体性能，因为它浪费了带宽和内存等公共资源。第三，预取文件给内存带来的压力更大，模型和数据的开销都要严格控制。
![image](https://user-images.githubusercontent.com/33679152/170818350-07aa2340-c9dd-4322-95ec-7c9d47dd4c4e.png)

### 【总结】
随着闪存从移动设备到大型数据中心的广泛使用，针对闪存特性而设计的闪存友好文件系统 (F2FS) 变得流行起来。但是，F2FS 由于其日志记录方案写入而遭受严重的清理开销。文件系统中不同热度的数据混合存储会加剧段清洗。我们提出了基于动态识别热度（M2H）的多日志延迟写入和修改段清理。M2H 通过文件块更新距离定义热度，并使用 K-means 聚类准确识别动态访问模式的热度。基于细粒度热度，我们设计了多日志延迟写入并修改了受害者段的选择和释放。热点元数据缓存用于减少由热点元数据管理和集群计算引起的开销。与现有的F2FS策略相比，M2H中的segment清理迁移块减少了36.05%~36.51%，文件系统带宽累计增加了69.52%~70.43%。






